{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Winter session project first call - s278425.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9EFtE3-KmGP"
      },
      "source": [
        "**Project - Winter session - Maria Margherita Lovera (s278425)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y93hSuHNO-if"
      },
      "source": [
        "Libraries and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ryk9DZQ29y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72592e1-84b0-4d72-a9b6-830f88294961"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import scipy.sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "# fill designation NaNs with the most frequent designation for each province/country and variety of wine\n",
        "def fill_NaN_des(df, designation):\n",
        "  count = 1\n",
        "  rows = len(df.index)\n",
        "  count_dict = {}\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rGenerating count dictionary for province and variety ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.notna(row[designation]):\n",
        "      key_list = [row[designation], row['province'], row['variety']]\n",
        "      key = tuple(key_list)\n",
        "      if key in count_dict.keys():\n",
        "        count_dict[key] += 1\n",
        "      else:\n",
        "        count_dict[key] = 1\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "  count = 1\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rFilling {designation} NaNs with respect to province and variety: ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.isna(row[designation]):\n",
        "      province = row['province']\n",
        "      variety = row['variety']\n",
        "      max_value = 0\n",
        "      max_key = tuple()\n",
        "      for key in count_dict.keys():\n",
        "        if (province in key) and (variety in key):\n",
        "          if count_dict[key] > max_value:\n",
        "            max_value = count_dict[key]\n",
        "            max_key = key\n",
        "\n",
        "      if len(max_key) != 0:\n",
        "        selected_designation = max_key[0]\n",
        "        df.at[index, designation] = selected_designation\n",
        "\n",
        "    count += 1\n",
        "  print()\n",
        "  print(\"Done.\")\n",
        "\n",
        "  count = 1\n",
        "  rows = len(df.index)\n",
        "  count_dict = {}\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rGenerating count dictionary for country and variety ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.notna(row[designation]):\n",
        "      key_list = [row[designation], row['country'], row['variety']]\n",
        "      key = tuple(key_list)\n",
        "      if key in count_dict.keys():\n",
        "        count_dict[key] += 1\n",
        "      else:\n",
        "        count_dict[key] = 1\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "  count = 1\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rFilling remaining {designation} NaNs with respect to country and variety: ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.isna(row[designation]):\n",
        "      country = row['country']\n",
        "      variety = row['variety']\n",
        "      max_value = 0\n",
        "      max_key = tuple()\n",
        "      for key in count_dict.keys():\n",
        "        if (country in key) and (variety in key):\n",
        "          if count_dict[key] > max_value:\n",
        "            max_value = count_dict[key]\n",
        "            max_key = key\n",
        "\n",
        "      if len(max_key) != 0:\n",
        "        selected_designation = max_key[0]\n",
        "        df.at[index, designation] = selected_designation\n",
        "\n",
        "    count += 1\n",
        "  print()\n",
        "  print(\"Done.\")\n",
        "\n",
        "\n",
        "# fill region_1 NaNs with the most frequent with respect to province and variety of wine\n",
        "def fill_NaN_reg1(df, region):\n",
        "  count = 1\n",
        "  rows = len(df.index)\n",
        "  count_dict = {}\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rGenerating count dictionary for province and variety ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.notna(row[region]):\n",
        "      key_list = [row[region], row['province'], row['variety']]\n",
        "      key = tuple(key_list)\n",
        "      if key in count_dict.keys():\n",
        "        count_dict[key] += 1\n",
        "      else:\n",
        "        count_dict[key] = 1\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "  count = 1\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rFilling {region} NaNs with respect to provinces and varieties: ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.isna(row[region]):\n",
        "      province = row['province']\n",
        "      variety = row['variety']\n",
        "      max_value = 0\n",
        "      max_key = tuple()\n",
        "      for key in count_dict.keys():\n",
        "        if (province in key) and (variety in key):\n",
        "          if count_dict[key] > max_value:\n",
        "            max_value = count_dict[key]\n",
        "            max_key = key\n",
        "\n",
        "      if len(max_key) != 0:\n",
        "        selected_region = max_key[0]\n",
        "        df.at[index, region] = selected_region\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "  print(f'We still have ' + str(df.isna().region_1.sum()) + ' NaNs to fill.')\n",
        "\n",
        "  count = 1\n",
        "  rows = len(df.index)\n",
        "  count_dict = {}\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rGenerating count dictionary for provinces ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.notna(row[region]):\n",
        "      key_list = [row[region], row['province']]\n",
        "      key = tuple(key_list)\n",
        "      if key in count_dict.keys():\n",
        "        count_dict[key] += 1\n",
        "      else:\n",
        "        count_dict[key] = 1\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "\n",
        "  count = 1\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rFilling {region} NaNs with respect to provinces: ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.isna(row[region]):\n",
        "      province = row['province']\n",
        "      max_value = 0\n",
        "      max_key = tuple()\n",
        "      for key in count_dict.keys():\n",
        "        if (province in key):\n",
        "          if count_dict[key] > max_value:\n",
        "            max_value = count_dict[key]\n",
        "            max_key = key\n",
        "\n",
        "      if len(max_key) != 0:\n",
        "        selected_region = max_key[0]\n",
        "        df.at[index, region] = selected_region\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  print()\n",
        "  print(f'We still have ' + str(df.isna().region_1.sum()) + ' NaNs to fill.')\n",
        "  \n",
        "  count = 1\n",
        "  for index, row in df.iterrows():\n",
        "    print(f\"\\rFilling {region} NaNs with correspondent province when no informations are given: ({100 * float(count) / rows}%)\", end='')\n",
        "    if pd.isna(row[region]):\n",
        "      province = row['province']\n",
        "      df.at[index, 'region_1'] = province\n",
        "    count += 1\n",
        "  print()\n",
        "  print(\"Done.\")\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8gdI88L6DC"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fk5YbXAKvhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1aa3a7-a1ba-4c40-e499-24e6d633a50e"
      },
      "source": [
        "# import dataframe\n",
        "data = pd.read_csv(\"dev.tsv\", sep = '\\t')\n",
        "\n",
        "# drop rows with NaNs on both country and province\n",
        "ind = data.loc[pd.isna(data[\"country\"]), :].index\n",
        "data = data.drop(ind).reset_index()\n",
        "data = data.drop(columns=['index'], axis = 1)\n",
        "\n",
        "# fill NaNs of designation\n",
        "print('Designation NaN filling')\n",
        "fill_NaN_des(data, 'designation')\n",
        "\n",
        "# drop rows with remaining NaNs on designation\n",
        "ind = data.loc[data['designation'].isna() == True].index\n",
        "data = data.drop(ind).reset_index()\n",
        "data = data.drop(columns=['index'], axis = 1)\n",
        "\n",
        "# fill NaNs of region_1\n",
        "print('Regions of group one NaN filling')\n",
        "fill_NaN_reg1(data, 'region_1')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating count dictionary for province and variety (100.0%)\n",
            "Filling designation NaNs with respect to province and variety: (100.0%)\n",
            "Done.\n",
            "Generating count dictionary for country and variety (100.0%)\n",
            "Filling remaining designation NaNs with respect to country and variety: (100.0%)\n",
            "Done.\n",
            "Generating count dictionary for province and variety (100.0%)\n",
            "Filling region_1 NaNs with respect to provinces and varieties: (100.0%)\n",
            "We still have 19028 NaNs to fill.\n",
            "Generating count dictionary for provinces (100.0%)\n",
            "Filling region_1 NaNs with respect to provinces: (100.0%)\n",
            "We still have 18575 NaNs to fill.\n",
            "Filling region_1 NaNs with correspondent province when no informations are given: (100.0%)\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8jQ0ARSL1jP"
      },
      "source": [
        "Model implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0TLCDuKLzKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59989568-8cd5-409c-ce24-6af342c02072"
      },
      "source": [
        "random.seed(1000)\n",
        "\n",
        "print('Preparing data:', end='')\n",
        "df = data[['description', 'winery', 'designation', 'region_1', 'variety']]\n",
        "target = data['quality']\n",
        "\n",
        "# train-test split for analysis\n",
        "X_train,X_test,y_train,y_test = train_test_split(df, target, test_size=0.20, random_state = 4)\n",
        "\n",
        "# Tf-idf on descriptions\n",
        "stop_words = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), analyzer = 'word', lowercase=True, stop_words = stop_words)\n",
        "print()\n",
        "print(\"Extracting tf-idf features of training set...\", end=\"\")\n",
        "X_train_descriptions = vectorizer.fit_transform(X_train['description'])\n",
        "print(f\"Done. Number of extracted features: {X_train_descriptions.shape[1]}\")\n",
        "print(\"Extracting tf-idf features of test set...\", end=\"\")\n",
        "X_test_descriptions = vectorizer.transform(X_test['description'])\n",
        "print('Done.')\n",
        "\n",
        "# wineries\n",
        "print(\"Binarization of remaining features...\", end=\"\")\n",
        "cvectw = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_train_wineries = cvectw.fit_transform(X_train['winery'])\n",
        "X_test_wineries = cvectw.transform(X_test['winery'])\n",
        "\n",
        "# designations\n",
        "cvectd = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_train_designations = cvectd.fit_transform(X_train['designation'])\n",
        "X_test_designations = cvectd.transform(X_test['designation'])\n",
        "\n",
        "# region_1\n",
        "cvectr = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_train_regions = cvectr.fit_transform(X_train['region_1'])\n",
        "X_test_regions = cvectr.transform(X_test['region_1'])\n",
        "\n",
        "# add varieties\n",
        "cvectv = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_train_varieties = cvectv.fit_transform(X_train['variety'])\n",
        "X_test_varieties = cvectv.transform(X_test['variety'])\n",
        "print('Done.')\n",
        "\n",
        "# make data for regression \n",
        "print('Construction of train set and test set for regression...', end='')\n",
        "X_train_reg = scipy.sparse.hstack((X_train_descriptions, X_train_wineries, X_train_designations, X_train_regions, X_train_varieties))\n",
        "X_test_reg = scipy.sparse.hstack((X_test_descriptions, X_test_wineries, X_test_designations, X_test_regions, X_test_varieties))\n",
        "\n",
        "print('Done.')\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data:\n",
            "Extracting tf-idf features of training set...Done. Number of extracted features: 612425\n",
            "Extracting tf-idf features of test set...Done.\n",
            "Binarization of remaining features...Done.\n",
            "Construction of train set and test set for regression...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7DrIKFuJCt-",
        "outputId": "0611fa30-5d6f-4b84-8a68-e2fd5a1165c0"
      },
      "source": [
        "# linear svr regression\n",
        "print('Starting LinearSVR regression...', end='')\n",
        "SVRreg = LinearSVR(C = 10, epsilon = 0.8, max_iter = 3000)\n",
        "SVRreg.fit(X_train_reg, y_train)\n",
        "SVRy_pred = SVRreg.predict(X_test_reg)\n",
        "print('Done. R2 score: ' + str(r2_score(y_test, SVRy_pred)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting LinearSVR regression...Done. R2 score: 0.8612190309457975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcWg158SNIoO"
      },
      "source": [
        "Model implementation on evaluation set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXdf2kjnNH7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9097b1-82d7-4125-85d2-4db57bc2e645"
      },
      "source": [
        "# import dataframe\n",
        "data_eval = pd.read_csv(\"eval.tsv\", sep = '\\t')\n",
        "\n",
        "# fill NaNs of designation\n",
        "print('Designation NaN filling')\n",
        "fill_NaN_des(data_eval, 'designation')\n",
        "\n",
        "# convert remaining NaNs of designation into strings\n",
        "# here it is not possible to drop rows since we are evaluating new data\n",
        "for index, row in data_eval.iterrows():\n",
        "  if pd.isna(row['designation']):\n",
        "    data_eval.at[index, 'designation'] = 'NaN'\n",
        "\n",
        "# fill NaNs of region_1\n",
        "print('Regions of group one NaN filling')\n",
        "fill_NaN_reg1(data_eval, 'region_1')\n",
        "\n",
        "\n",
        "################# data preprocessing for model implementation #####################\n",
        "random.seed(1100)\n",
        "print('Preparing data...', end='')\n",
        "dataframe = data[['description', 'winery', 'designation', 'region_1', 'variety']]\n",
        "dataframe_eval = data_eval[['description', 'winery', 'designation', 'region_1', 'variety']]\n",
        "target = data['quality']\n",
        "\n",
        "# Tf-idf on descriptions\n",
        "vectorizerdef = TfidfVectorizer(ngram_range=(1,2), analyzer = 'word', lowercase=True, stop_words = stop_words)\n",
        "print(\"Extracting tf-idf features of dev set...\", end=\"\")\n",
        "X_descriptions = vectorizerdef.fit_transform(dataframe['description'])\n",
        "print(f\"Done. Number of extracted features (unique stemmed words): {X_descriptions.shape[1]}\")\n",
        "print(\"Extracting tf-idf features of eval set...\", end=\"\")\n",
        "X_descriptions_eval = vectorizerdef.transform(dataframe_eval['description'])\n",
        "print('Done.')\n",
        "\n",
        "# wineries\n",
        "print(\"Binarization of remaining features...\", end=\"\")\n",
        "cvectwdef = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_wineries = cvectwdef.fit_transform(dataframe['winery'])\n",
        "X_wineries_eval = cvectwdef.transform(dataframe_eval['winery'])\n",
        "\n",
        "# designations\n",
        "cvectddef = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_designations = cvectddef.fit_transform(dataframe['designation'])\n",
        "X_designations_eval = cvectddef.transform(dataframe_eval['designation'])\n",
        "\n",
        "# region_1\n",
        "cvectrdef = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_regions = cvectrdef.fit_transform(dataframe['region_1'])\n",
        "X_regions_eval = cvectrdef.transform(dataframe_eval['region_1'])\n",
        "\n",
        "# varieties\n",
        "cvectvdef = CountVectorizer(lowercase = False, ngram_range = (1,2), binary = True)\n",
        "X_varieties = cvectvdef.fit_transform(dataframe['variety'])\n",
        "X_varieties_eval = cvectvdef.transform(dataframe_eval['variety'])\n",
        "print('Done.')\n",
        "\n",
        "\n",
        "# make data for regression \n",
        "print('Construction of dev set and eval set for regression...', end='')\n",
        "X_def = scipy.sparse.hstack((X_descriptions, X_wineries, X_designations, X_regions, X_varieties))\n",
        "X_def_eval = scipy.sparse.hstack((X_descriptions_eval, X_wineries_eval, X_designations_eval, X_regions_eval, X_varieties_eval))\n",
        "print('Done.')\n",
        "\n",
        "# linear svr regression\n",
        "print(\"Starting regression...\", end=\"\")\n",
        "linreg_def = LinearSVR(C=10, epsilon = 0.8, max_iter = 3000).fit(X_def, target)\n",
        "y_pred_def = linreg_def.predict(X_def_eval)\n",
        "print('Done.')\n",
        "\n",
        "# sample submission\n",
        "id = np.arange(len(y_pred_def))\n",
        "sub = {'Id': id, 'Predicted': y_pred_def}\n",
        "submission = pd.DataFrame(sub)\n",
        "# submission.to_csv('sample_submission.csv', index = False) "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Designation NaN filling\n",
            "Generating count dictionary for province and variety (100.0%)\n",
            "Filling designation NaNs with respect to province and variety: (100.0%)\n",
            "Done.\n",
            "Generating count dictionary for country and variety (100.0%)\n",
            "Filling remaining designation NaNs with respect to country and variety: (100.0%)\n",
            "Done.\n",
            "Regions of group one NaN filling\n",
            "Generating count dictionary for province and variety (100.0%)\n",
            "Filling region_1 NaNs with respect to provinces and varieties: (100.0%)\n",
            "We still have 4871 NaNs to fill.\n",
            "Generating count dictionary for provinces (100.0%)\n",
            "Filling region_1 NaNs with respect to provinces: (100.0%)\n",
            "We still have 4862 NaNs to fill.\n",
            "Filling region_1 NaNs with correspondent province when no informations are given: (100.0%)\n",
            "Done.\n",
            "Preparing data...Extracting tf-idf features of dev set...Done. Number of extracted features (unique stemmed words): 680482\n",
            "Extracting tf-idf features of eval set...Binarization of remaining features...Done.\n",
            "Construction of dev set and eval set for regression...Done.\n",
            "Starting regression...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}